---
title: Research Log Update
date: 2026-02-16T00:08:14.908668
timestamp: 2026-02-16 00:08:14
tricks: 104
proposals: 62
experiments: 33
---

I'll analyze this massive activity dump systematically. Let me explore the key files for deeper context on the most important experiments and proposals.Read the following files and summarize their key findings concisely:
1. /home/bkitano/Desktop/vault/projects/mad-architecture-search/proposals/002-ssd-deltanet-wy-hybrid.md
2. /home/bkitano/Desktop/vault/projects/mad-architecture-search/proposals/022-displacement-rank-ssm-state-transitions.md
3. /home/bkitano/Desktop/vault/projects/mad-architecture-search/proposals/029-circulant-favor-plus-linear-attention.md
4. /home/bkitano/Desktop/vault/projects/mad-architecture-search/proposals/011-neumann-resolvent-chunkwise-ssm.md
5. /home/bkitano/Desktop/vault/projects/mad-architecture-search/proposals/025-nystrom-landmark-chunkwise-ssm.md
6. /home/bkitano/Desktop/vault/projects/mad-architecture-search/proposals/004-oscillatory-dplr-ssm.md
7. /home/bkitano/Desktop/vault/projects/mad-architecture-search/proposals/007-oscillatory-gated-selective-ssm.md
8. /home/bkitano/Desktop/vault/projects/mad-architecture-search/proposals/005-segmented-hss-linear-attention.md
9. /home/bkitano/Desktop/vault/projects/mad-architecture-search/proposals/012-expert-choice-monarch-ssm-heads.md
10. /home/bkitano/Desktop/vault/projects/mad-architecture-search/proposals/021-blackbox-hss-telescopic-attention-compression.md
11. /home/bkitano/Desktop/vault/projects/mad-architecture-search/proposals/026-cyclic-reduction-randmscan-ssm-recurrence.md

For each, tell me: status, key result (success/fail/partial), and what was learned.Search for and read any results files or experiment logs for the ongoing experiments. Look for files matching these patterns:
- /home/bkitano/Desktop/vault/projects/mad-architecture-search/experiments/experiment-log-*.md
- /home/bkitano/Desktop/vault/projects/mad-architecture-search/proposals/*_results.md
- /home/bkitano/Desktop/vault/projects/mad-architecture-search/experiments/*_results.md

Specifically I want to know: what experiments have been completed and what were their results? Also check for:
- 002_results.md
- 004_results.md
- 005_results.md
- 007_results.md
- 011_results.md
- 012_results.md
- 021_results.md
- 022_results.md
- 025_results.md
- 026_results.md
- 029_results.md
- 006_results.md

Focus on: did the experiment succeed or fail? What was the actual finding? What was the cost?Read the following recently-created proposal files to understand what they're proposing and estimate their compute cost. For each, give me: hypothesis (1 sentence), estimated GPU cost, and novelty assessment.

1. /home/bkitano/Desktop/vault/projects/mad-architecture-search/proposals/060-fused-post-sigmoid-gating-chunkwise-linear-rnn.md
2. /home/bkitano/Desktop/vault/projects/mad-architecture-search/proposals/059-second-order-kda-hla-key-metric.md
3. /home/bkitano/Desktop/vault/projects/mad-architecture-search/proposals/056-flashmask-tile-skip-chunkwise-linear-rnn.md
4. /home/bkitano/Desktop/vault/projects/mad-architecture-search/proposals/053-mla-latent-state-linear-rnn-inference.md
5. /home/bkitano/Desktop/vault/projects/mad-architecture-search/proposals/043-newton-schulz-orthogonal-deltanet-transition.md
6. /home/bkitano/Desktop/vault/projects/mad-architecture-search/proposals/061-stablessm-decay-reparam-kda-gla.md
7. /home/bkitano/Desktop/vault/projects/mad-architecture-search/proposals/062-fused-intra-token-deltaproduct-householder-steps.md
8. /home/bkitano/Desktop/vault/projects/mad-architecture-search/proposals/009-post-sigmoid-gating-linear-attention.md

Focus on which can be validated cheaply (<$10) and which have the highest novelty.Now let me write the log entry:Now I have full context. Let me write the comprehensive update log.The update log has been generated and written to `/home/bkitano/Desktop/vault/projects/mad-architecture-search/experiments/update-log-2026-02-16.md`.

Here's the executive summary:

## Key Takeaways

**ðŸ”¥ Top Priority Action: Run Experiment 009 (Post-Sigmoid Gating)**
- <$0.50 cost, already implemented, backed by NeurIPS Best Paper
- 2 lines of code that could give 5-15% quality lift on all linear RNN architectures

**ðŸ“Š Scorecard: 9 completed experiments, 44% hit rate, $0.50 total spend**
- **Winners**: OscGate-SSM (selectivity works), NystrÃ¶m compression (co-adaptation), Cyclic reduction (3.9Ã— speedup), Neumann resolvent
- **Failures**: DR-SSM (optimization barriers), HSS (GPU-unfriendly), FAVOR+ (feature maps are the bottleneck), Expert-Choice MoE SSM (routing kills gradients)
- **New failure**: Exp 012 (Expert-Choice Monarch) â€” discrete routing inside recurrent dynamics doesn't work

**ðŸš€ 10 experiments currently running** (7 kernel optimizations + 3 architecture explorations), reflecting the project's shift from "what architecture?" to "how to make it fast?"

**ðŸ’¡ Highest-impact new proposals:**
1. **Proposal 009** (post-sigmoid gating) â€” cheapest, highest expected value
2. **Proposal 059** (Second-Order KDA) â€” most novel combination, already running
3. **Proposal 061** (StableSSM reparameterization) â€” zero overhead, proven theory

**ðŸ“ Meta-pattern emerging: "co-adaptation beats approximation"** â€” design for learnability, not initialization quality
