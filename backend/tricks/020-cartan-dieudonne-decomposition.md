# 020: Cartan-Dieudonné Decomposition

**Category**: algebraic
**Gain type**: expressivity
**Source**: Élie Cartan (1938), Jean Dieudonné (1940)
**Paper**: [papers/cartan-dieudonne-decomposition.pdf] (Gallier, algorithmic construction)
**Documented**: 2026-02-11

## Description

The Cartan-Dieudonné theorem establishes that **every orthogonal transformation** in an $n$-dimensional space can be decomposed as a product of **at most $n$ reflections** (Householder transformations). This is the foundational result that connects Householder reflections to the full orthogonal group $O(n)$, and it has a direct analog for permutations: every permutation in $S_n$ can be decomposed into at most $n - 1$ transpositions. Both results say that "atomic involutions generate the full group," and the bound is tight.

For neural networks, this theorem is the theoretical backbone for:
1. **Householder product parameterizations** — using $k \leq n$ reflections to parameterize a subgroup of $O(n)$
2. **Understanding expressivity vs. depth trade-offs** — fewer reflections = smaller reachable subset of $O(n)$
3. **Connecting permutation simulation to Householder count** — DeltaProduct's result that $n_h$ reflections can simulate $S_{n_h+1}$ is a constructive application of Cartan-Dieudonné

The theorem also applies over general fields and to the more general class of isometries of non-degenerate symmetric bilinear forms (the Cartan-Dieudonné-Scherk theorem).

## Mathematical Form

**Core Theorem (Cartan-Dieudonné):**

Let $V$ be an $n$-dimensional vector space over a field $K$ (with $\text{char}(K) \neq 2$) equipped with a non-degenerate symmetric bilinear form. Then every isometry $\varphi \in O(V)$ can be written as a composition of at most $n$ reflections:

$$
\varphi = H_{v_1} \circ H_{v_2} \circ \cdots \circ H_{v_k}, \quad k \leq n
$$

where each $H_v$ is the reflection in the hyperplane orthogonal to $v$:

$$
H_v(x) = x - 2\frac{\langle x, v \rangle}{\langle v, v \rangle} v
$$

**Key Definitions:**

- $O(n, \mathbb{R})$ — the orthogonal group: $\{Q \in \mathbb{R}^{n \times n} : Q^\top Q = I\}$
- $SO(n)$ — the special orthogonal group (rotations): $\{Q \in O(n) : \det(Q) = +1\}$
- $H_v = I - 2\frac{vv^\top}{v^\top v}$ — Householder reflection matrix for vector $v$
- $k = n - \dim(\text{Fix}(\varphi))$ — the number of reflections needed equals $n$ minus the dimension of the fixed-point subspace

**Determinant and parity:**

$$
\det\left(\prod_{i=1}^k H_{v_i}\right) = (-1)^k
$$

So:
- $k$ even $\Rightarrow$ rotation ($\det = +1$, element of $SO(n)$)
- $k$ odd $\Rightarrow$ improper rotation ($\det = -1$)

**Parallel to permutations:**

| Orthogonal Group $O(n)$ | Symmetric Group $S_n$ |
|-------------------------|----------------------|
| Generated by reflections $H_v$ | Generated by transpositions $(ij)$ |
| At most $n$ reflections needed | At most $n - 1$ transpositions needed |
| $\det(Q) = (-1)^k$ for $k$ reflections | $\text{sgn}(\sigma) = (-1)^k$ for $k$ transpositions |
| $SO(n)$: even number of reflections | $A_n$: even number of transpositions |
| Reflections are involutions: $H_v^2 = I$ | Transpositions are involutions: $(ij)^2 = e$ |

**Constructive algorithm (Gallier):**

Given $Q \in O(n)$, compute the decomposition:

1. If $Q = I$, done (zero reflections)
2. Find $v_1 = Qe_1 - e_1$ (or $Qe_1 + e_1$ if this is zero)
3. Compute $H_{v_1} Q$ — this fixes $e_1$
4. Recurse on the $(n-1) \times (n-1)$ submatrix

This produces at most $n$ reflection vectors in $O(n^2)$ total work.

## Complexity

| Operation | Direct | Via Cartan-Dieudonné |
|-----------|--------|---------------------|
| Store orthogonal $Q$ | $O(n^2)$ | $O(nk)$ with $k \leq n$ reflection vectors |
| Mat-vec $Qx$ | $O(n^2)$ | $O(nk)$ applying $k$ reflections sequentially |
| Decompose $Q$ into reflections | — | $O(n^2)$ (constructive algorithm) |
| Compose reflections into $Q$ | $O(n^2 k)$ | — |
| Full group reachable? | Yes | Yes, with $k = n$ |
| Subgroup with $k < n$ | Dimension $nk - k(k+1)/2$ | Smooth manifold in $O(n)$ |

**Memory:** $O(nk)$ for $k$ reflection vectors vs $O(n^2)$ for a dense matrix

## Applicability

- **Householder-product neural networks:** The theorem guarantees that with $n$ reflections, any orthogonal matrix is reachable; with $k < n$, a smooth $k$-dimensional family is traversed — the foundation of Mhammedi et al. (2017) and DeltaProduct
- **Orthogonal RNN transitions:** Constraining to $k$ reflections gives gradient-friendly orthogonal matrices with $O(nk)$ parameters and $O(nk)$ mat-vec cost
- **Understanding permutation simulation:** Since every transposition is a Householder reflection (with $v = (e_i - e_j)/\sqrt{2}$), the Cartan-Dieudonné bound implies that $k$ reflections can represent any permutation that decomposes into $\leq k$ transpositions
- **QR factorization:** The classical Householder QR algorithm is a direct application: it applies $n - 1$ Householder reflections to triangularize a matrix
- **Lie group theory:** The theorem connects $O(n)$ to its root system and Weyl group, with applications in equivariant neural networks

## Limitations

- The decomposition is not unique — there are infinitely many ways to choose the reflection vectors
- With $k < n$ reflections, the reachable set is a proper submanifold of $O(n)$; the topology of this submanifold can create training difficulties (local optima)
- The constructive algorithm is sequential (each step depends on the previous), limiting parallelism
- Over fields of characteristic 2, the theorem fails (reflections don't generate the full orthogonal group)
- Does not directly apply to non-orthogonal matrices; for general $GL(n)$, a different decomposition is needed

## Implementation Notes

```python
import torch

def cartan_dieudonne_decompose(Q):
    """
    Decompose orthogonal matrix Q into a product of Householder reflections.
    Returns list of reflection vectors v_1, ..., v_k such that
    Q = H_{v_1} @ H_{v_2} @ ... @ H_{v_k}

    Complexity: O(n^2)
    """
    n = Q.shape[0]
    vectors = []
    R = Q.clone()

    for i in range(n):
        # Extract the i-th column of remaining submatrix
        x = R[i:, i].clone()

        # Construct Householder vector to map x to ||x|| * e_1
        norm_x = torch.norm(x)
        if norm_x < 1e-12:
            continue

        # Choose sign to avoid cancellation
        sign = 1.0 if x[0] >= 0 else -1.0
        x[0] += sign * norm_x
        x = x / torch.norm(x)

        # Embed in full space
        v = torch.zeros(n)
        v[i:] = x
        vectors.append(v)

        # Apply reflection to R
        R = R - 2.0 * torch.outer(v, v @ R)

    return vectors


def compose_householder(vectors, x):
    """
    Apply product of Householder reflections to vector x.
    H_{v_1} @ H_{v_2} @ ... @ H_{v_k} @ x
    Applied in reverse order (rightmost first).
    """
    result = x.clone()
    for v in reversed(vectors):
        result = result - 2.0 * v * torch.dot(v, result)
    return result
```

## References

- Cartan, É. (1938). Leçons sur la théorie des spineurs.
- Dieudonné, J. (1940). Sur les groupes classiques.
- Gallier, J. (2011). An algorithm for the Cartan-Dieudonné theorem on generalized scalar product spaces. arXiv:1011.1027.
- Mhammedi et al. (2017). Efficient Orthogonal Parametrisation of Recurrent Neural Networks Using Householder Reflections. ICML 2017.
- Schlag et al. (2025). DeltaProduct: Improving State-Tracking in Linear RNNs via Householder Products. ICLR 2025.
