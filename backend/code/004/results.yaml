analysis:
  omega_gt_mean: !!python/object/apply:numpy._core.multiarray.scalar
  - &id001 !!python/object/apply:numpy.dtype
    args:
    - f8
    - false
    - true
    state: !!python/tuple
    - 3
    - <
    - null
    - null
    - null
    - -1
    - -1
    - 0
  - !!binary |
    thjKlHQrrD8=
  omega_gt_std: !!python/object/apply:numpy._core.multiarray.scalar
  - *id001
  - !!binary |
    4oZShLtImj8=
  omega_learned:
  - 0.05308932811021805
  - 0.053461313247680664
  - 0.06831814348697662
  - 0.013625170104205608
  - 0.04312172904610634
  - 0.05465719848871231
  - 0.019304441288113594
  - 0.016464075073599815
  - 0.09561006724834442
  - 0.07528162002563477
  - 0.09258285164833069
  - 0.061526596546173096
  - 0.0639013797044754
  - 0.0116928955540061
  - 0.05402199178934097
  - 0.02147776447236538
  omega_learned_max: !!python/object/apply:numpy._core.multiarray.scalar
  - &id002 !!python/object/apply:numpy.dtype
    args:
    - f4
    - false
    - true
    state: !!python/tuple
    - 3
    - <
    - null
    - null
    - null
    - -1
    - -1
    - 0
  - !!binary |
    Ns/DPQ==
  omega_learned_mean: !!python/object/apply:numpy._core.multiarray.scalar
  - *id002
  - !!binary |
    rVJMPQ==
  omega_learned_min: !!python/object/apply:numpy._core.multiarray.scalar
  - *id002
  - !!binary |
    j5M/PA==
  omega_learned_std: !!python/object/apply:numpy._core.multiarray.scalar
  - *id002
  - !!binary |
    XoXWPA==
  zeta_gt_mean: !!python/object/apply:numpy._core.multiarray.scalar
  - *id001
  - !!binary |
    POHyKM7n3z8=
  zeta_gt_std: !!python/object/apply:numpy._core.multiarray.scalar
  - *id001
  - !!binary |
    uJWIw/g8xj8=
  zeta_learned:
  - 0.3541647791862488
  - 0.38083213567733765
  - 0.7050259113311768
  - 0.49831926822662354
  - 0.5567768812179565
  - 0.34158575534820557
  - 0.6899130344390869
  - 0.5763946771621704
  - 0.5187737345695496
  - 0.6538411378860474
  - 0.5651446580886841
  - 0.4033574163913727
  - 0.2603452503681183
  - 0.5825181007385254
  - 0.669954776763916
  - 0.3856087028980255
  zeta_learned_mean: !!python/object/apply:numpy._core.multiarray.scalar
  - *id002
  - !!binary |
    6UcCPw==
  zeta_learned_std: !!python/object/apply:numpy._core.multiarray.scalar
  - *id002
  - !!binary |
    /uwJPg==
config:
  data:
    num_test: 1000
    num_train: 8000
    num_val: 1000
    omega_range:
    - 0.01
    - 0.1
    test_len: 512
    train_len: 128
    zeta_range:
    - 0.2
    - 0.8
  model:
    d_input: 1
    d_output: 1
    dt: 0.01
    init_omega_range:
    - 0.01
    - 0.1
    n: 16
    r: 2
  seed: 42
  training:
    batch_size: 32
    epochs: 50
    lr: 0.001
    weight_decay: 0.0001
success_criteria:
  extrapolation: false
  interpretability: !!python/object/apply:numpy._core.multiarray.scalar
  - !!python/object/apply:numpy.dtype
    args:
    - b1
    - false
    - true
    state: !!python/tuple
    - 3
    - '|'
    - null
    - null
    - null
    - -1
    - -1
    - 0
  - !!binary |
    AQ==
  train_fit: false
test_loss: 0.7592529468238354
train_losses:
- 0.8544054991006851
- 0.8543924777507782
- 0.8543713186979294
- 0.8543748154640197
- 0.8543727974891663
- 0.8543732318878173
- 0.8543700178861618
- 0.8543908042907715
- 0.8543650900125503
- 0.8543736667633056
- 0.854368667602539
- 0.8543822917938232
- 0.8543609540462493
- 0.8543622212409974
- 0.8543673979043961
- 0.8543826062679291
- 0.854373627781868
- 0.8543630676269531
- 0.8543807476758957
- 0.8543694614171982
- 0.8543686085939407
- 0.8543614521026611
- 0.8543794234991073
- 0.85437118434906
- 0.8543832471370697
- 0.8543598138093949
- 0.8543665254116058
- 0.8543586200475692
- 0.8543646974563599
- 0.8543709754943848
- 0.8543639602661133
- 0.8543711919784546
- 0.8543620468378067
- 0.854368506193161
- 0.8543670777082443
- 0.8543626129627228
- 0.854378248333931
- 0.8543641351461411
- 0.8543640551567078
- 0.8543705005645752
- 0.8543649754524231
- 0.8543552054166794
- 0.8543560843467712
- 0.8543578639030457
- 0.8543618055582046
- 0.8543738667964935
- 0.8543594238758088
- 0.8543646581172943
- 0.854359430193901
- 0.8543714421987534
val_losses:
- 0.88573401235044
- 0.8858319241553545
- 0.8858508002012968
- 0.8858778942376375
- 0.8858938105404377
- 0.8858821466565132
- 0.885866217315197
- 0.8860018346458673
- 0.8859119787812233
- 0.8859642166644335
- 0.8858454655855894
- 0.8859222326427698
- 0.8859786204993725
- 0.8859175872057676
- 0.8860130049288273
- 0.8860095907002687
- 0.8860040754079819
- 0.8859556801617146
- 0.8859844114631414
- 0.8859464805573225
- 0.8859414644539356
- 0.8859575036913157
- 0.8859844021499157
- 0.8859570939093828
- 0.8859216831624508
- 0.8859374020248652
- 0.885920288041234
- 0.8859396353363991
- 0.8858662080019712
- 0.8859463687986135
- 0.8859535772353411
- 0.8858893234282732
- 0.8859275933355093
- 0.88593421690166
- 0.8859381023794413
- 0.8859239537268877
- 0.8858608976006508
- 0.8859154656529427
- 0.885918078944087
- 0.8859089277684689
- 0.885909553617239
- 0.8858975674957037
- 0.8859023936092854
- 0.8859132416546345
- 0.8858955968171358
- 0.8859601616859436
- 0.8859347179532051
- 0.8859195709228516
- 0.8859196100383997
- 0.8859699163585901
verdict: DEBUG
