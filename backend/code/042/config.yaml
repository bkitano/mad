# Experiment 042: Contraction-Ordered Multi-Operand Chunkwise GLA Fusion
# Pure kernel microbenchmark - no model training

sweep:
  chunk_sizes: [32, 64, 128]
  head_dims: [64, 128, 256]
  ranks: [1, 4, 8, 16]  # r=C is added automatically
  alpha_mins: [0.9, 0.99, 0.999]  # Decay rate ranges [alpha_min, 1.0]
  batch_size: 64
  n_warmup: 20
  n_trials: 100
  batched: true  # Use batched matmuls for realistic GPU utilization

logging:
  wandb_project: "mad-architecture-search"

deployment:
  n_gpus: 1
  gpu_type: "A100"
  timeout_seconds: 1800  # 30 min max
